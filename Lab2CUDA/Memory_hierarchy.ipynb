{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Memory hierarchy",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8DNxrbtFQiM"
      },
      "source": [
        "#Memory hierarchy\n",
        "\n",
        "##Notebook setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jLI8_N_E2cj"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "870frpZiFFuE"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int main() {\n",
        "    int numDevs=0;\n",
        "    cudaGetDeviceCount(&numDevs);\n",
        "    cudaDeviceProp prop;\n",
        "    cudaGetDeviceProperties(&prop, 0);\n",
        "    printf(\"Device Number: %d\\n\", 0);\n",
        "    printf(\"  Device name: %s\\n\", prop.name);\n",
        "    printf(\"  Memory Clock Rate (KHz): %d\\n\",\n",
        "          prop.memoryClockRate);\n",
        "    printf(\"  Memory Bus Width (bits): %d\\n\",\n",
        "          prop.memoryBusWidth);\n",
        "    printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "          2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    printf(\"Num devices %d\\n\", numDevs);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKfhXyEvFc28"
      },
      "source": [
        "#Device, Shared and Private memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XozjoFf4FLXr"
      },
      "source": [
        "%%cuda --name test.cu\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "#define VECTOR_SIZE 128\n",
        "#define BLOCK_SIZE 128\n",
        "\n",
        "void __global__ nonSharedReverseOrder(int* input, int* output, int vectorSize) {\n",
        "    // Vars input and output contain a memory addres that will be copied to each thread.\n",
        "    // The address will reside in private memory, but it will point to Device memory.\n",
        "    // Var vectorSize, contains a value that resides in private memory, and will\n",
        "    // be copied to each thread.\n",
        "\n",
        "    for (int i=0; i<vectorSize; ++i) {\n",
        "        output[(vectorSize-1)-i] = input[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "extern __shared__ int sharedMemory[];\n",
        "void __global__ sharedDynamicReverseOrder(int* input, int* output, int vectorSize) {\n",
        "    int* input_sh = sharedMemory;\n",
        "    int* output_sh = sharedMemory + blockDim.x;\n",
        "\n",
        "    input_sh[threadIdx.x] = input[threadIdx.x];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        for (int i=0; i<vectorSize; ++i) {\n",
        "            output_sh[(vectorSize-1)-i] = input_sh[i];\n",
        "        }\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    output[threadIdx.x] = output_sh[threadIdx.x];\n",
        "}\n",
        "\n",
        "void __global__ sharedStaticReverseOrder(int* input, int* output, int vectorSize) {\n",
        "    __shared__ int input_sh[BLOCK_SIZE];\n",
        "    __shared__ int output_sh[BLOCK_SIZE];\n",
        "\n",
        "    input_sh[threadIdx.x] = input[threadIdx.x];\n",
        "    __syncthreads();\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        for (int i=0; i<vectorSize; ++i) {\n",
        "            output_sh[(vectorSize-1)-i] = input_sh[i];\n",
        "        }\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    output[threadIdx.x] = output_sh[threadIdx.x];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *h_in, *h_out, *d_in, *d_out;\n",
        "\n",
        "    // If we create the host memory with CUDA,\n",
        "    // the transfers between GPU and CPU are faster\n",
        "    cudaMallocHost(&h_in, VECTOR_SIZE*sizeof(int));\n",
        "    cudaMallocHost(&h_out, VECTOR_SIZE*sizeof(int));\n",
        "\n",
        "    cudaMalloc(&d_in, VECTOR_SIZE*sizeof(int));\n",
        "    cudaMalloc(&d_out, VECTOR_SIZE*sizeof(int));\n",
        "\n",
        "    for (int i=0; i<VECTOR_SIZE; ++i) {\n",
        "        h_in[i] = i;\n",
        "    }\n",
        "\n",
        "    cudaStream_t stream;\n",
        "    cudaStreamCreate(&stream);\n",
        "\n",
        "    cudaMemcpyAsync(d_in, h_in, VECTOR_SIZE*sizeof(int), cudaMemcpyHostToDevice, stream);\n",
        "    \n",
        "    /*dim3 block(1);\n",
        "    dim3 grid(1);\n",
        "    nonSharedReverseOrder<<<grid, block, 0, stream>>>(d_in, d_out, VECTOR_SIZE);*/\n",
        "    \n",
        "    dim3 block(BLOCK_SIZE);\n",
        "    dim3 grid(1);\n",
        "    sharedStaticReverseOrder<<<grid, block, 0, stream>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "    /*size_t sharedSize = BLOCK_SIZE * sizeof(int) * 2;\n",
        "    dim3 block(BLOCK_SIZE);\n",
        "    dim3 grid(1);\n",
        "    sharedDynamicReverseOrder<<<grid, block, sharedSize, stream>>>(d_in, d_out, VECTOR_SIZE);*/\n",
        "\n",
        "    cudaMemcpyAsync(h_out, d_out, VECTOR_SIZE*sizeof(int), cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    cudaStreamSynchronize(stream);\n",
        "\n",
        "    std::cout << \"Result: \";\n",
        "    for (int i=0; i<VECTOR_SIZE; ++i) {\n",
        "        std::cout << h_out[i] << \" \"; \n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlgG_iymRCIk"
      },
      "source": [
        "!nvcc /content/src/test.cu -o test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5886c9ERH1j"
      },
      "source": [
        "!./test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsfyKkZfRJy1"
      },
      "source": [
        "!nvprof ./test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLxiZNVpNj5-"
      },
      "source": [
        "#Multi Thread block version\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyl4Uyi3RMe2"
      },
      "source": [
        "%%cuda --name testBig.cu\n",
        "\n",
        "#include <iostream>\n",
        "\n",
        "#define VECTOR_SIZE 100000000\n",
        "#define BLOCK_SIZE 128\n",
        "\n",
        "void __global__ nonSharedReverseOrderBig(int* input, int* output, int vectorSize) {\n",
        "    // Compute the input global index taking into account the blockId\n",
        "    // Take also into account that we are only usind a thread per block\n",
        "    int inputGIdx = blockIdx.x * BLOCK_SIZE;\n",
        "\n",
        "    for (int i=inputGIdx; i<(inputGIdx + BLOCK_SIZE) && i<vectorSize; ++i) {\n",
        "        output[(vectorSize - 1) - i] = input[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "extern __shared__ int sharedMemory[];\n",
        "void __global__ sharedDynamicReverseOrderBig(int* input, int* output, int vectorSize, int modulus) {\n",
        "    int* input_sh = sharedMemory;\n",
        "    int* output_sh = sharedMemory + blockDim.x;\n",
        "\n",
        "    // Compute the input global index, taking into account the thread block\n",
        "    int inputGIdx = threadIdx.x + (blockIdx.x * blockDim.x);\n",
        "\n",
        "    if (inputGIdx < vectorSize) {\n",
        "      input_sh[threadIdx.x] = input[inputGIdx];\n",
        "    }\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x == 0) {\n",
        "        for (int i=0; i < BLOCK_SIZE && (inputGIdx + i) < vectorSize; ++i) {\n",
        "            output_sh[(BLOCK_SIZE - 1) - i] = input_sh[i];\n",
        "        }\n",
        "    }\n",
        "    __syncthreads();\n",
        "\n",
        "    \n",
        "    // Compute the output global index, taking into account the reverse order\n",
        "    // of the thread blocks\n",
        "    int outputGIdx = threadIdx.x + (((gridDim.x - 1) - blockIdx.x) * blockDim.x);\n",
        "    if (blockIdx.x != gridDim.x -1) {\n",
        "        outputGIdx -= modulus;\n",
        "        output[outputGIdx] = output_sh[threadIdx.x];\n",
        "    } else {\n",
        "        if (outputGIdx >= modulus) {\n",
        "          output[outputGIdx - modulus] = output_sh[threadIdx.x];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *h_in, *h_out, *d_in, *d_out;\n",
        "\n",
        "    // If we create the host memory with CUDA,\n",
        "    // the transfers between GPU and CPU are faster\n",
        "    cudaMallocHost(&h_in, VECTOR_SIZE*sizeof(int));\n",
        "    cudaMallocHost(&h_out, VECTOR_SIZE*sizeof(int));\n",
        "\n",
        "    cudaMalloc(&d_in, VECTOR_SIZE*sizeof(int));\n",
        "    cudaMalloc(&d_out, VECTOR_SIZE*sizeof(int));\n",
        "\n",
        "    for (int i=0; i<VECTOR_SIZE; ++i) {\n",
        "        h_in[i] = i;\n",
        "    }\n",
        "\n",
        "    cudaStream_t stream;\n",
        "    cudaStreamCreate(&stream);\n",
        "\n",
        "    cudaMemcpyAsync(d_in, h_in, VECTOR_SIZE*sizeof(int), cudaMemcpyHostToDevice, stream);\n",
        "\n",
        "    dim3 block(1);\n",
        "    dim3 grid(ceil(VECTOR_SIZE / (float)BLOCK_SIZE));\n",
        "    nonSharedReverseOrderBig<<<grid, block, 0, stream>>>(d_in, d_out, VECTOR_SIZE);\n",
        "\n",
        "    /*size_t sharedSize = BLOCK_SIZE * sizeof(int) * 2;\n",
        "    dim3 block(BLOCK_SIZE);\n",
        "    dim3 grid(ceil(VECTOR_SIZE/(float)BLOCK_SIZE));\n",
        "    int modulus = BLOCK_SIZE - (VECTOR_SIZE % BLOCK_SIZE);\n",
        "    sharedDynamicReverseOrderBig<<<grid, block, sharedSize, stream>>>(d_in, d_out, VECTOR_SIZE, modulus);*/\n",
        "\n",
        "    cudaMemcpyAsync(h_out, d_out, VECTOR_SIZE*sizeof(int), cudaMemcpyDeviceToHost, stream);\n",
        "\n",
        "    cudaStreamSynchronize(stream);\n",
        "\n",
        "    std::cout << \"Result: \";\n",
        "    for (int i=0; i<VECTOR_SIZE; ++i) {\n",
        "        std::cout << h_out[i] << \" \"; \n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB8iRMYTVspU"
      },
      "source": [
        "!nvcc /content/src/testBig.cu -o testBig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJL9laN9V6oD"
      },
      "source": [
        "!./testBig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q5n5CC5WV_7a"
      },
      "source": [
        "!nvprof ./testBig"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}